#!/usr/bin/env python3
"""
T√©l√©chargement RAPIDE avec 10 t√©l√©chargements simultan√©s
"""

import json
import requests
import os
import time
from pathlib import Path
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

def clean_filename(filename):
    """Nettoie le nom de fichier"""
    forbidden_chars = '<>:"/\\|?*'
    for char in forbidden_chars:
        filename = filename.replace(char, '_')
    filename = re.sub(r'\s+', '_', filename)
    if len(filename) > 200:
        filename = filename[:200]
    return filename

def fix_url(url):
    """Corrige les URLs malform√©es"""
    if url.startswith('https://,'):
        url = url[8:]
    return url.strip()

# Variables globales pour le suivi
lock = threading.Lock()
stats = {'success': 0, 'error': 0, 'skipped': 0, 'total': 0}

def download_single_pdf(args):
    """T√©l√©charge un seul PDF"""
    i, convention, extraction_folder, downloaded_files = args
    
    try:
        idcc = convention.get('IDCC', '').strip()
        nom = convention.get('Nom De la Convention', 'Sans titre').strip()
        url = convention.get('Link', '').strip()
        
        if not url or url == " ":
            with lock:
                stats['skipped'] += 1
            return f"[{i}] ‚è≠Ô∏è Pas d'URL: {nom}"
        
        # Cr√©er nom de fichier
        if idcc and idcc != " ":
            filename = f"{idcc}_{nom}.pdf"
        else:
            filename = f"{nom}.pdf"
        
        clean_name = clean_filename(filename)
        
        # V√©rifier si d√©j√† t√©l√©charg√©
        if clean_name in downloaded_files:
            with lock:
                stats['skipped'] += 1
            return f"[{i}] ‚úÖ D√©j√† t√©l√©charg√©: {clean_name}"
        
        # Cr√©er session pour ce thread
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # T√©l√©charger
        url = fix_url(url)
        response = session.get(url, timeout=20)
        response.raise_for_status()
        
        # Sauvegarder
        file_path = extraction_folder / clean_name
        with open(file_path, 'wb') as f:
            f.write(response.content)
        
        size_mb = len(response.content) / (1024*1024)
        
        with lock:
            stats['success'] += 1
            
        return f"[{i}] ‚úÖ {clean_name} ({size_mb:.1f} MB)"
        
    except Exception as e:
        with lock:
            stats['error'] += 1
        return f"[{i}] ‚ùå Erreur {nom}: {str(e)[:50]}"

def main():
    print("üöÄ T√âL√âCHARGEMENT RAPIDE AVEC 10 THREADS PARALL√àLES")
    print("=" * 60)
    
    # Configuration
    EXTRACTION_FOLDER = Path("extraction_2025-09-24")
    JSON_FILE = "attached_assets/conventions_collectives_integrales_lienpdf_nettoye_1755080256357.json"
    MAX_WORKERS = 10  # 10 t√©l√©chargements simultan√©s !
    
    # Charger les donn√©es
    with open(JSON_FILE, 'r', encoding='utf-8') as f:
        conventions = json.load(f)
    
    stats['total'] = len(conventions)
    print(f"üìã Total conventions: {len(conventions)}")
    
    # Fichiers d√©j√† t√©l√©charg√©s
    EXTRACTION_FOLDER.mkdir(exist_ok=True)
    downloaded_files = {f for f in os.listdir(EXTRACTION_FOLDER) if f.endswith('.pdf')}
    print(f"üìÅ D√©j√† t√©l√©charg√©s: {len(downloaded_files)}")
    print(f"‚ö° T√©l√©chargement parall√®le avec {MAX_WORKERS} threads")
    print()
    
    start_time = time.time()
    
    # Pr√©parer les arguments pour chaque thread
    tasks = []
    for i, convention in enumerate(conventions, 1):
        tasks.append((i, convention, EXTRACTION_FOLDER, downloaded_files))
    
    # Lancer le t√©l√©chargement parall√®le
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Soumettre toutes les t√¢ches
        futures = {executor.submit(download_single_pdf, task): task for task in tasks}
        
        # Traiter les r√©sultats au fur et √† mesure
        for future in as_completed(futures):
            result = future.result()
            print(result)
            
            # Afficher progression tous les 20 t√©l√©chargements
            total_processed = stats['success'] + stats['error'] + stats['skipped']
            if total_processed % 20 == 0:
                elapsed = time.time() - start_time
                speed = total_processed / elapsed if elapsed > 0 else 0
                remaining = stats['total'] - total_processed
                eta = remaining / speed if speed > 0 else 0
                
                print(f"\nüìä Progression: {total_processed}/{stats['total']} "
                      f"({total_processed/stats['total']*100:.1f}%)")
                print(f"‚ö° Vitesse: {speed:.1f} PDFs/seconde")
                print(f"‚è±Ô∏è  ETA: {eta/60:.1f} minutes")
                print(f"‚úÖ Succ√®s: {stats['success']}, ‚ùå Erreurs: {stats['error']}, "
                      f"‚è≠Ô∏è  Ignor√©s: {stats['skipped']}")
                print("-" * 40)
    
    # R√©sultats finaux
    elapsed = time.time() - start_time
    print("\n" + "=" * 60)
    print("üèÅ T√âL√âCHARGEMENT TERMIN√â!")
    print("=" * 60)
    print(f"‚è±Ô∏è  Temps total: {elapsed/60:.1f} minutes")
    print(f"‚úÖ Succ√®s: {stats['success']}")
    print(f"‚ùå Erreurs: {stats['error']}")
    print(f"‚è≠Ô∏è  Ignor√©s (d√©j√† t√©l√©charg√©s): {stats['skipped']}")
    print(f"‚ö° Vitesse moyenne: {stats['success']/elapsed:.1f} PDFs/seconde")
    
    # V√©rification finale
    final_count = len([f for f in os.listdir(EXTRACTION_FOLDER) if f.endswith('.pdf')])
    print(f"üìÅ Total PDFs dans le dossier: {final_count}")

if __name__ == "__main__":
    main()